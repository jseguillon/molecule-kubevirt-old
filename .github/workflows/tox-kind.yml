name: Docker

on:
  workflow_dispatch:
  pull_request:

jobs:
  docker:
    name: Docker
    runs-on: ubuntu-20.04
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        ipFamily: [ipv4, ipv6]
        exclude:
          - ipFamily: ipv6
    env:
      JOB_NAME: "kind-${{ matrix.deployment }}-${{ matrix.ipFamily }}"
      IP_FAMILY: ${{ matrix.ipFamily }}
    steps:
      - name: Check out code 
        uses: actions/checkout@v2

      - name: Enable ipv4 and ipv6 forwarding
        run: |
          sudo sysctl -w net.ipv6.conf.all.forwarding=1
          sudo sysctl -w net.ipv4.ip_forward=1

      - name: Install docker
        run: |
          . /etc/os-release
          ## FIXME Workaround for https://github.com/kubernetes/kubernetes/issues/61058
          ### And https://github.com/LiliC/travis-minikube/blob/e0f26f7b388057f51a0e2558afd5f990e07b6c49/.travis.yml#L11
          sudo mount --make-rshared /
          ### conntrack is required by kube 1.18
          sudo apt-get update
          sudo apt-get install -y conntrack
          # sudo systemctl stop apparmor
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
          sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
          sudo apt-get update
          sudo apt-get -y -o Dpkg::Options::="--force-confnew" install docker-ce
          sudo apt install -y qemu qemu-kvm libvirt-daemon libvirt-clients bridge-utils virt-manager libvirt-daemon-system dnsmasq
          sudo systemctl restart libvirtd
          # Install network
          sudo mkdir -p /etc/cni/net.d
          # curl -qsSL https://raw.githubusercontent.com/containers/libpod/master/cni/87-podman-bridge.conflist | sudo tee /etc/cni/net.d/87-podman-bridge.conf
          curl -qsSL https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz --output /tmp/cni.tgz
          sudo mkdir -p /usr/libexec/cni
          sudo tar -C /usr/libexec/cni -xvzf /tmp/cni.tgz

      - name: Tweak Ubuntu apparmor
        run: |
          sudo cat /etc/apparmor.d/usr.sbin.libvirtd
          tweak_qemu_apprarmor="$(head -n -1 /etc/apparmor.d/usr.sbin.libvirtd; echo "  /usr/libexec/qemu-kvm rmix,"; tail -1 /etc/apparmor.d/usr.sbin.libvirtd)"
          echo "$tweak_qemu_apprarmor"
          echo "$tweak_qemu_apprarmor" | sudo dd of=/etc/apparmor.d/usr.sbin.libvirtd 
          sudo cat /etc/apparmor.d/usr.sbin.libvirtd 
          sudo systemctl reload apparmor.service

      - name: Install kubectl
        run: |
          curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.20.0/bin/linux/amd64/kubectl; chmod +x ./kubectl
          sudo install kubectl /usr/local/bin

      - name: Install kind
        run: |
          curl -Lo ./kind "https://kind.sigs.k8s.io/dl/v0.9.0/kind-$(uname)-amd64" && chmod +x ./kind 
          sudo install kind /usr/local/bin
          # Need kubectl

      - name: Create single node cluster
        run: |
          cat <<EOF | sudo kind create cluster -v7 --wait 1m --retain --config=-
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          networking:
            ipFamily: ${IP_FAMILY}
          EOF

      - name: Get Cluster status
        run: |
          # wait network is ready
          sudo kubectl wait --for=condition=ready pods --namespace=kube-system -l k8s-app=kube-dns
          sudo kubectl get nodes -o wide
          sudo kubectl get pods -A

      - name: Install kubevirt
        run: |          
          sudo kubectl create -f https://github.com/kubevirt/kubevirt/releases/download/v0.36.0/kubevirt-operator.yaml
          sudo kubectl create configmap kubevirt-config -n kubevirt --from-literal debug.useEmulation=true
          sudo kubectl create -f https://github.com/kubevirt/kubevirt/releases/download/v0.36.0/kubevirt-cr.yaml

      - name: Install virtcl
        run: |          
          export ARCH=linux-amd64
          curl -L -o virtctl https://github.com/kubevirt/kubevirt/releases/download/v0.36.0/virtctl-v0.36.0-${ARCH}
          chmod +x virtctl
          sudo install virtctl /usr/local/bin

      - name: Build molecule test container 
        run: |
          docker build . --file tools/Dockerfile  -t molecule_kubevirt:latest
          sudo kind load docker-image molecule_kubevirt:latest

      - name: Push molecule test to Kind 
        run: |
          sudo kind load docker-image molecule_kubevirt:latest

      - name: Install kail 
        run: | 
          curl -SL https://github.com/boz/kail/releases/download/v0.15.0/kail_0.15.0_linux_amd64.tar.gz -o kail.tar.gz
          tar xf kail.tar.gz
          sudo install kail /usr/local/bin

      - name: Get Kubevirt status
        run: |
          # wait network is ready
          sudo kubectl wait --for=condition=ready pods --namespace=kubevirt -l kubevirt.io=virt-operator 
          sleep 30
          sudo kubectl wait --for=condition=ready pods --namespace=kubevirt -l kubevirt.io=virt-api || true
          sudo kubectl wait --for=condition=ready pods --namespace=kubevirt -l kubevirt.io=virt-controller || true
          sudo kubectl wait --for=condition=ready pods --namespace=kubevirt -l kubevirt.io=virt-handler || true
          sudo kubectl get nodes -o wide
          sudo kubectl get pods -A

      - name: Start test Job
        run: | 
          sudo kubectl create -f tools/test-rolebinding.yaml
          # Create a configmap github will be to be deleted, telling one Pod ended the Job
          sudo kubectl create configmap molecule-job-running --from-literal status=Started
          sudo kubectl apply -f tools/test-job.yaml

      - name: Wait for Job to end and log Pods in default namespace
        run: | 
          # Wait for Job Pod to start
          sudo kubectl wait --for=condition=ready pods -l job-name=molecule --namespace default
          # Send console log to both :(  need async wait pod being created
          ( sleep 180 && sudo sh -c 'true | (setsid virtctl console instance) 2>&1 | tee /tmp/virtcl.txt' || true ) &
          # Kail sends any logs from default namespace both to stdout and a log file
          ( sudo kail -n default 2>&1 | tee /tmp/kail.log || true ) &
          # Wait for molecule Job to delete configmap and notify one Job Pod as ran till the end
          sudo kubectl wait --for delete --timeout=15m  configmap/molecule-job-running
          # Exit of github action is the one set by molecule job in config map result
          exit $(sudo kubectl get configmap molecule-result -o "jsonpath={.data['exitCode']}")

      - name: Export logs
        if: always()
        run: |
          mkdir -p /tmp/kind/logs
          sleep 30;
          sudo kubectl get events > /tmp/kind/logs/events.txt || true
          sudo kubectl describe jobs > /tmp/kind/logs/jobs.txt || true
          sudo kubectl describe cm > /tmp/kind/logs/cm.txt
          cp /tmp/kail.log /tmp/kind/logs || true
          cp /tmp/describes.txt /tmp/kind/logs || true
          sudo cp /tmp/virtcl.txt /tmp/kind/logs || true
          sudo dmesg > /tmp/kind/logs/dmesg.txt
          sudo kind export logs /tmp/kind/logs
          sudo journalctl | cat > /tmp/kind/logs/journalctl.txt
          sudo chown -R $USER:$USER /tmp/kind/logs

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v2
        with:
          name: kind-logs-${{ env.JOB_NAME }}-${{ github.run_id }}
          path: /tmp/kind/logs
